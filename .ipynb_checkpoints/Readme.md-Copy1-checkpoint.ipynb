{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self Driving car Advanced Lane line \n",
    "\n",
    "\n",
    "\n",
    "#### The aim of the project \n",
    "     * Using computer vision for various taskes \n",
    "        1 Measuring distortion\n",
    "        2 Calibrating Camera\n",
    "        3 Correction for distortion\n",
    "        5 Use color transforms\n",
    "        6 Apply a perspective transform to rectify binary image (\"birds-eye view\")\n",
    "        7 Detect lane pixels and fit to find the lane boundary\n",
    "        8 Determine the curvature of the lane\n",
    "        9 Warp the detected lane boundaries back onto the original image\n",
    "        10 O/P the lane image with estimates of curved and boundary defined for accurate path for car to stay on the\n",
    "        path \n",
    "    \n",
    "    \n",
    "-----    \n",
    "            \n",
    "#### Rubric Point\n",
    "    * Here I will consider the rubric points individually and describe how I addressed each point in my \n",
    "      implementation.\n",
    "      \n",
    "##### File Submission and Code qualiy\n",
    "    \n",
    "    File submission inculde all the required files that are necessary to quialy the project submission\n",
    "    \n",
    "       1) project.ipynb\n",
    "       2) Readme.md\n",
    "       3) Writeup.up\n",
    "    \n",
    "#### Below are the steps described individually that are implement in the project \n",
    "        \n",
    "        1) Finding corners\n",
    "        \n",
    "        2) Camera calibration\n",
    "\n",
    "        4) Perspective Transform to bird's eye view\n",
    "        \n",
    "        5) Binary lane line image using gradient and color transforms\n",
    "        \n",
    "        6) Sobel Utilisation\n",
    "        \n",
    "        6) Identifying lane line pixels using sliding windows\n",
    "\n",
    "        7) Extracting the local curvature of the road and vehicle localization\n",
    "\n",
    "        8) Projecting the detected lane lines onto the original image\n",
    "        \n",
    "        9) Video Processing Pipeline\n",
    "\n",
    "###### 1) Finding corners\n",
    "\n",
    "Corders of the chess board are spoted so that the further calibration can be done.\n",
    "\n",
    "\n",
    "\n",
    "##### 2) Camera calibration\n",
    "\n",
    "Image distortion occurs when a camera looks at 3D objects in the real world and transforms them into a 2D image; this transformation isnâ€™t perfect. Distortion actually changes what the shape and size of these 3D objects appear to be. So, the first step in analyzing camera images, is to undo this distortion so that you can get correct and useful information out of them.\n",
    "\n",
    "\n",
    "\n",
    "####  Test Image Pipeline\n",
    "<img src='output_images/undistorted.png' />\n",
    "\n",
    "##### 3)Example of a distortion corrected image\n",
    "Applying the undistortion transformation to a test image yields the following result (left distorted, right corrected) \n",
    "\n",
    "<img src=\"output_images/undistort_traffic_img.png\" />\n",
    "\n",
    "##### 4) Perspective Transform to bird's eye view\n",
    "A perspective transform to and from \"bird's eye\" perspective is done in a function called warp(), The warp() function takes as input an color image (img), as well as the tobird boolean paramter. The parameters src and  dst of the transform.\n",
    "\n",
    "<img src=\"output_images/unwarped.png\" />\n",
    "\n",
    "##### 5) Binary lane line image using gradient and color transforms\n",
    "\n",
    "color traformation was done using RGB , HSV and HLS below is the image porduced after the color transformation\n",
    "\n",
    "<img src = \"output_images/color_depth.png\" />\n",
    "\n",
    "##### 6) Sobel Utilisation\n",
    "\n",
    "    I used variouts sobel Operators in order to find the image details\n",
    "    \n",
    "    1) absolute Sobel threshold\n",
    "<img src =\"output_images/sobel_threshold.png\" width='500'/>\n",
    "    2. magnitue threshold\n",
    "<img src =\"output_images/sobel_magnitued.png\" width='500'/>\n",
    "    3. direction threshold\n",
    "<img src =\"output_images/sobel_mag_and_dir.png\" width='500' />\n",
    "\n",
    "\n",
    "#### Identifying lane line pixels using sliding windows\n",
    "\n",
    "\n",
    "depending upon the threshold the image pixel were recognised and sliding window was implemented in order to get results, The bootom of the image was recognised and pipline filted was run over in order to get the accurate results, further cuvers were recognised on each fram and x along with y value was recognised on which green shade was build over \n",
    "<img src =\"output_images/sliding_window_rectangle.png\" width='300' />  <img src =\"output_images/sliding_window2.png\" width='300' />  <img src=\"output_images/sliding_window_rectangle.png\" width=\"300\" />\n",
    "\n",
    "\n",
    "##### 7) mExtracting the local curvature of the road and vehicle localization\n",
    "\n",
    "The radius of curvature is computed upon calling the Line.update() method of a line. The method that does the computation is called Line.get_radius_of_curvature(). The mathematics involved is summarized in this tutorial here.\n",
    "For a second order polynomial f(y)=A y^2 +B y + C the radius of curvature is given by R = [(1+(2 Ay +B)^2 )^3/2]/|2A|.\n",
    "\n",
    "The distance from the center of the lane is computed in the Line.set_line_base_pos() method, which essentially measures the distance to each lane and computes the position assuming the lane has a given fixed width of 3.7m.\n",
    "<img src=\"output_images/embeding_curv.png\" width=\"300\" />\n",
    "\n",
    "#### Video Processing Pipeline\n",
    "\n",
    "ALL the gathered knowledge was applied into single piple line and result was achieved \n",
    "\n",
    "\n",
    "\n",
    "<video width=\"400\" controls>\n",
    "  <source src=\"project_video.mp4\" type=\"video/mp4\">\n",
    "\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:self_drive]",
   "language": "python",
   "name": "conda-env-self_drive-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
